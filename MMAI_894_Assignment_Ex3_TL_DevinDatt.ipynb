{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMAI_894_Assignment_Ex3_TL_DevinDatt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devindatt/NLP_Transfer_Learning/blob/main/MMAI_894_Assignment_Ex3_TL_DevinDatt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x906-fBJSYi"
      },
      "source": [
        "# Info and Instructions\r\n",
        "\r\n",
        "## 1 Your Objective (**Read Carefully**)\r\n",
        "The year is 2051, fake news has drastically destabilized our political system.\r\n",
        "70% of Canadians believe at least one of the major conspiracy theories circulating the country at any given time.\r\n",
        "\r\n",
        "A new type of political party has developed (lets call them Party Q), that relies heavily on fake news and country division and fear\r\n",
        "to win the support of voters. \r\n",
        "Party Q has been gaining major traction in Canadian politics at all levels, \r\n",
        "and certain provinces are currently being occupied by Party Q Political candidates.\r\n",
        "\r\n",
        "The current prime-minister is a stable moderate but there are fears around the rising support for the\r\n",
        "a Party Q opposition even at the federal level.\r\n",
        "\r\n",
        "You've been asked by the Canadian Government to build a proof of concept model to detect fake news. \r\n",
        "If successful this model will be deployed and applied to every political speech/comment/post made in this country\r\n",
        "at all levels of government, it will be used for both real-time fact checking, and flagging of facts to be sent to proffessional fact checkers.\r\n",
        "\r\n",
        "The fate of our nation rests in your capable hands.\r\n",
        "\r\n",
        "The prime minister needs 3 results from your model:\r\n",
        "1. Needs to flag false posts (\"pants-fire\" or \"false\") with a recall of at least 70% (these will be sent to proffessional fact checkers)\r\n",
        "2. Needs to flag \"true\" posts with a precision of at least 95% (these will be used in real-time to verify facts during presentations)\r\n",
        "3. Needs to flag \"pants-fire\" posts with a precision of at least 95% (these will be used in real-time to contradict statements during presentations)\r\n",
        "(See dataset information for more clarification around labels)\r\n",
        "\r\n",
        "## 2 Dataset Information:\r\n",
        "\"We consider six fine-grained labels for\r\n",
        "the truthfulness ratings: pants-fire, false, barelytrue, half-true, mostly-true, and true. The distribution of labels in the LIAR dataset is relatively\r\n",
        "well-balanced: except for 1,050 pants-fire cases,\r\n",
        "the instances for all other labels range from 2,063\r\n",
        "to 2,638.\" - https://arxiv.org/pdf/1705.00648.pdf\r\n",
        "\r\n",
        "## 3 Submission Instructions (**Read Carefully**)\r\n",
        "- To submit:\r\n",
        "  1. you cannot edit this notebook directly. **Save a copy** to your drive, and make sure to identify yourself in the title using name and student number\r\n",
        "  2. **Ensure** you have implemented all the nececessary functions\r\n",
        "  3. **Provide answers** to the questions in the conclusion cell\r\n",
        "  4. Unlike previous assignments, please **submit all three formats: .py, .ipynb, and html** (see https://torbjornzetterlund.com/how-to-save-a-google-colab-notebook-as-html/)\r\n",
        "    - The notebook and html submissions should show the completion of your best performing run\r\n",
        "  5. **Ensure** your nNotebook can _restart and run all_\r\n",
        "  6. The mark will be assessed on the implementation of the functions with #TODO\r\n",
        "  7. **Do not change anything outside the marked functions**  unless in the further exploration section\r\n",
        "  8.  Do not use any additional libraries than the ones listed below (you may import additional modules from those libraries if needed)\r\n",
        "  9. The mark is primarily based on correctness. However, since you are responsible for optimally tuning this model, meeting high performance is required, you should be able to at least match the results given in the paper.\r\n",
        "\r\n",
        "Changing your run time in colab to GPU will speed up the training drastically\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA53XTYaEZ35",
        "outputId": "0b1bf3df-d8bb-43e9-deb1-c26cfe66e439"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install pandas"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.2)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZj4c0xTeMwH"
      },
      "source": [
        "from datasets import load_dataset\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow.keras as keras\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "try: # this is only working on the 2nd try in colab :)\r\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel\r\n",
        "except Exception as err: # so we catch the error and import it again\r\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "\r\n",
        "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCfW4gzbza2m"
      },
      "source": [
        ""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NZXY-9zZa7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfIsoKKAJ1nq"
      },
      "source": [
        "# Data Preparation\r\n",
        "\r\n",
        "## Clean the text and your targets\r\n",
        "Hints: \r\n",
        "1. Use the exploration cell to explore the data and identify cleaning steps\r\n",
        "2. Inspect the tokenized sentences and ensure they make sense and can leverage already trained word embeddings\r\n",
        "3. These resources will help you understand what type of cleaning will be required and how you can encode your text for the network:\r\n",
        "    - a) Preprocessing: https://huggingface.co/transformers/preprocessing.html\r\n",
        "    - b) Summary of tokenizers (DistilBERT uses WordPiece): https://huggingface.co/transformers/tokenizer_summary.html#wordpiece\r\n",
        "4. Consider the text length, is this too big/small for DistilBERT? what impact would padding/truncation have?\r\n",
        "5. In load data you generated a profiling report of this dataset, might be helpful to review that as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT9xsN3eezI6"
      },
      "source": [
        "def prepare_raw_data(df):\r\n",
        "  raw_data = df.loc[:, [\"id\", \"statement\", \"label\"]]\r\n",
        "  raw_data[\"label\"] = raw_data[\"label\"].astype('category')\r\n",
        "  return raw_data\r\n",
        "\r\n",
        "def load_data(save_dir=\"./\"):\r\n",
        "  dataset = load_dataset(\"liar\")\r\n",
        "  train = prepare_raw_data(pd.DataFrame(dataset[\"train\"]))\r\n",
        "  val = prepare_raw_data(pd.DataFrame(dataset[\"validation\"]))\r\n",
        "  test = prepare_raw_data(pd.DataFrame(dataset[\"test\"]))\r\n",
        "  return train, val, test\r\n",
        "         \r\n",
        "def clean_data(raw_data):\r\n",
        "  # TODO: What data cleaning/filtering should you consider?\r\n",
        "  # Hint: check for duplicates or contradictions\r\n",
        "  # Hint: What is the minimum and maximum lengths of the statements?\r\n",
        "  # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  clean_data = raw_data\r\n",
        "\r\n",
        "  return clean_data\r\n",
        "\r\n",
        "def extract_raw_text_and_y(clean_data):\r\n",
        "  raw_text, raw_y = clean_data[\"statement\"].values, clean_data[\"label\"].values\r\n",
        "  return raw_text, raw_y\r\n",
        "\r\n",
        "def encode_text(text):\r\n",
        "    # TODO: encode text using dbert_tokenizer\r\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "\r\n",
        "    encoded_input = dbert_tokenizer(text, return_tensors=\"tf\")\r\n",
        "#    outputs = model(**inputs)\r\n",
        "    print(encoded_input)\r\n",
        "    input_ids = encoded_input['input_ids']\r\n",
        "    attention_mask = encoded_input['attention_mask']\r\n",
        "\r\n",
        "    return input_ids, attention_mask\r\n",
        "#    return 0\r\n",
        "\r\n",
        "#encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\r\n",
        "#{'input_ids': [101, 138, 18696, 155, 1942, 3190, 1144, 1572, 13745, 1104, 159, 9664, 2107, 102],\r\n",
        "# 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\r\n",
        "# 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\r\n",
        "\r\n",
        "\r\n",
        "def prepare_target(raw_y):\r\n",
        "    # TODO: convert labels to 0/1\r\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "    # NOTE: labels map as follows: ['false', 'half-true', 'mostly-true', 'true', 'barely-true', 'pants-fire']\r\n",
        "    # y should have:\r\n",
        "    # column 0 = \"pants-fire\" or \"false\" posts\r\n",
        "    # column 1 = \"true\" posts\r\n",
        "    # column 2 = \"pants-fire\"\r\n",
        "\r\n",
        "    df = pd.DataFrame(raw_y, columns=['labels'])\r\n",
        "  \r\n",
        "    df['column_0'] = np.select([df['labels'].isin([0,1])], [1])#, default=0)\r\n",
        "    df['column_1'] = np.select([df['labels'].isin([2,3,4,5])], [1])#, default=0)\r\n",
        "    df['column_2'] = np.select([df['labels'].eq(0)], [1])#, default=0)\r\n",
        "\r\n",
        "    y = df.drop('labels', axis=1)\r\n",
        "\r\n",
        "    return y\r\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnNw8ko1P3eS",
        "outputId": "caa3349a-628c-4e61-dfcf-d26bf5622601"
      },
      "source": [
        "load_data()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset liar (/root/.cache/huggingface/datasets/liar/default/1.0.0/1a6abd9863f27194da30fcb66988477abfa3780df3b0ad1d0032979c48ec7918)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(               id                                          statement label\n",
              " 0       2635.json  Says the Annies List political group supports ...     0\n",
              " 1      10540.json  When did the decline of coal start? It started...     1\n",
              " 2        324.json  Hillary Clinton agrees with John McCain \"by vo...     2\n",
              " 3       1123.json  Health care reform legislation is likely to ma...     0\n",
              " 4       9028.json  The economic turnaround started at the end of ...     1\n",
              " ...           ...                                                ...   ...\n",
              " 10264   5473.json  There are a larger number of shark attacks in ...     2\n",
              " 10265   3408.json  Democrats have now become the party of the [At...     2\n",
              " 10266   3959.json  Says an alternative to Social Security that op...     1\n",
              " 10267   2253.json  On lifting the U.S. Cuban embargo and allowing...     0\n",
              " 10268   1155.json  The Department of Veterans Affairs has a manua...     5\n",
              " \n",
              " [10269 rows x 3 columns],\n",
              "               id                                          statement label\n",
              " 0     12134.json  We have less Americans working now than in the...     4\n",
              " 1       238.json  When Obama was sworn into office, he DID NOT u...     5\n",
              " 2      7891.json  Says Having organizations parading as being so...     0\n",
              " 3      8169.json     Says nearly half of Oregons children are poor.     1\n",
              " 4       929.json  On attacks by Republicans that various program...     1\n",
              " ...          ...                                                ...   ...\n",
              " 1279   3419.json  For the first time in more than a decade, impo...     1\n",
              " 1280  12548.json  Says Donald Trump has bankrupted his companies...     2\n",
              " 1281    401.json  John McCain and George Bush have \"absolutely n...     3\n",
              " 1282   1055.json  \"A new poll shows 62 percent support the presi...     0\n",
              " 1283   9117.json  No one claims the report vindicating New Jerse...     4\n",
              " \n",
              " [1284 rows x 3 columns],\n",
              "               id                                          statement label\n",
              " 0     11972.json  Building a wall on the U.S.-Mexico border will...     3\n",
              " 1     11685.json  Wisconsin is on pace to double the number of l...     0\n",
              " 2     11096.json  Says John McCain has done nothing to help the ...     0\n",
              " 3      5209.json  Suzanne Bonamici supports a plan that will cut...     1\n",
              " 4      9524.json  When asked by a reporter whether hes at the ce...     5\n",
              " ...          ...                                                ...   ...\n",
              " 1278   7334.json  Says his budget provides the highest state fun...     1\n",
              " 1279   9788.json                    Ive been here almost every day.     4\n",
              " 1280  10710.json  In the early 1980s, Sen. Edward Kennedy secret...     4\n",
              " 1281   3186.json  Says an EPA permit languished under Strickland...     4\n",
              " 1282   6743.json  Says the governor is going around the state ta...     0\n",
              " \n",
              " [1283 rows x 3 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvapv3LXOzj0",
        "outputId": "d759f90f-bf5b-4505-e0c1-8d7632395c6a"
      },
      "source": [
        "train, val, test = load_data()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset liar (/root/.cache/huggingface/datasets/liar/default/1.0.0/1a6abd9863f27194da30fcb66988477abfa3780df3b0ad1d0032979c48ec7918)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yna4CdRlOzxS"
      },
      "source": [
        "raw_train = prepare_raw_data(train)\n",
        "raw_val = prepare_raw_data(val)\n",
        "raw_test = prepare_raw_data(test)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWsZuoyBWbnf",
        "outputId": "1580081b-153c-49d7-ec4e-65f36d983bc8"
      },
      "source": [
        "raw_train['label'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2123\n",
              "0    1998\n",
              "2    1966\n",
              "3    1683\n",
              "4    1657\n",
              "5     842\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTfKzv4HqSiC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1APrxLHZWIv"
      },
      "source": [
        "train_raw_x, train_raw_y = extract_raw_text_and_y(clean_data(raw_train))\n",
        "val_raw_x, val_raw_y = extract_raw_text_and_y(clean_data(raw_val))\n",
        "test_raw_x, test_raw_y = extract_raw_text_and_y(clean_data(raw_test))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX4LSQ3mZWO2",
        "outputId": "759a8a32-662a-4e57-abec-b37a3155d075"
      },
      "source": [
        "train_raw_x"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Says the Annies List political group supports third-trimester abortions on demand.',\n",
              "       'When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.',\n",
              "       'Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"',\n",
              "       ...,\n",
              "       'Says an alternative to Social Security that operates in Galveston County, Texas, has meant that participants will retire with a whole lot more money than under Social Security.',\n",
              "       'On lifting the U.S. Cuban embargo and allowing travel to Cuba.',\n",
              "       \"The Department of Veterans Affairs has a manual out there telling our veterans stuff like, 'Are you really of value to your community?' You know, encouraging them to commit suicide.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5aRqt_NqZ_vZ",
        "outputId": "cfbac9e4-0ede-4e05-d700-8f2ab0c29848"
      },
      "source": [
        "prepare_target(train_raw_y)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_0</th>\n",
              "      <th>column_1</th>\n",
              "      <th>column_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10264</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10265</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10266</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10267</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10268</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10269 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       column_0  column_1  column_2\n",
              "0             1         0         1\n",
              "1             1         0         0\n",
              "2             0         1         0\n",
              "3             1         0         1\n",
              "4             1         0         0\n",
              "...         ...       ...       ...\n",
              "10264         0         1         0\n",
              "10265         0         1         0\n",
              "10266         1         0         0\n",
              "10267         1         0         1\n",
              "10268         0         1         0\n",
              "\n",
              "[10269 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TVDHfqihqnzx",
        "outputId": "adc5da9c-073f-4d7d-9219-642c3a96dda9"
      },
      "source": [
        "prepare_target(val_raw_y)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_0</th>\n",
              "      <th>column_1</th>\n",
              "      <th>column_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1282</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1283</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1284 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      column_0  column_1  column_2\n",
              "0            0         1         0\n",
              "1            0         1         0\n",
              "2            1         0         1\n",
              "3            1         0         0\n",
              "4            1         0         0\n",
              "...        ...       ...       ...\n",
              "1279         1         0         0\n",
              "1280         0         1         0\n",
              "1281         0         1         0\n",
              "1282         1         0         1\n",
              "1283         0         1         0\n",
              "\n",
              "[1284 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "UdwUJR5KZ_0H",
        "outputId": "1c9bf6ef-b167-4bc5-aaef-3cc8eb9efb93"
      },
      "source": [
        "prepare_target(test_raw_y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_0</th>\n",
              "      <th>column_1</th>\n",
              "      <th>column_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1282</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1283 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      column_0  column_1  column_2\n",
              "0            0         1         0\n",
              "1            1         0         1\n",
              "2            1         0         1\n",
              "3            1         0         0\n",
              "4            0         1         0\n",
              "...        ...       ...       ...\n",
              "1278         1         0         0\n",
              "1279         0         1         0\n",
              "1280         0         1         0\n",
              "1281         0         1         0\n",
              "1282         1         0         1\n",
              "\n",
              "[1283 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7w8Z0wtZ_7n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkhV8U1zZyr-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDwR9z_2ZWVm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2owVURPZVg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Nhs2L96vOz8M",
        "outputId": "72835009-0b55-4519-d90b-6556372f66b1"
      },
      "source": [
        "raw_val = prepare_raw_data(val)\n",
        "raw_val.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12134.json</td>\n",
              "      <td>We have less Americans working now than in the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>238.json</td>\n",
              "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7891.json</td>\n",
              "      <td>Says Having organizations parading as being so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8169.json</td>\n",
              "      <td>Says nearly half of Oregons children are poor.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>929.json</td>\n",
              "      <td>On attacks by Republicans that various program...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                          statement label\n",
              "0  12134.json  We have less Americans working now than in the...     4\n",
              "1    238.json  When Obama was sworn into office, he DID NOT u...     5\n",
              "2   7891.json  Says Having organizations parading as being so...     0\n",
              "3   8169.json     Says nearly half of Oregons children are poor.     1\n",
              "4    929.json  On attacks by Republicans that various program...     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QrAPDPKsO0DS",
        "outputId": "da58f3d0-e225-4b5f-d715-2df858380be0"
      },
      "source": [
        "raw_test = prepare_raw_data(test)\n",
        "raw_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11685.json</td>\n",
              "      <td>Wisconsin is on pace to double the number of l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11096.json</td>\n",
              "      <td>Says John McCain has done nothing to help the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5209.json</td>\n",
              "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9524.json</td>\n",
              "      <td>When asked by a reporter whether hes at the ce...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                          statement label\n",
              "0  11972.json  Building a wall on the U.S.-Mexico border will...     3\n",
              "1  11685.json  Wisconsin is on pace to double the number of l...     0\n",
              "2  11096.json  Says John McCain has done nothing to help the ...     0\n",
              "3   5209.json  Suzanne Bonamici supports a plan that will cut...     1\n",
              "4   9524.json  When asked by a reporter whether hes at the ce...     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEQJAGPhO0KA",
        "outputId": "78c5fd22-f76f-46de-c5fb-68c84ed72726"
      },
      "source": [
        "test_text = \"Hello, I'm a single sentence!\"\n",
        "input_ids, attention_mask = encode_text(test_text)\n",
        "print(input_ids)\n",
        "print(attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=\n",
            "array([[ 101, 7592, 1010, 1045, 1005, 1049, 1037, 2309, 6251,  999,  102]],\n",
            "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
            "tf.Tensor([[ 101 7592 1010 1045 1005 1049 1037 2309 6251  999  102]], shape=(1, 11), dtype=int32)\n",
            "tf.Tensor([[1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 11), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5ZMhB56O0Sr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2USajN2MWjn"
      },
      "source": [
        "# Modelling\r\n",
        "\r\n",
        "## Build and Train Model\r\n",
        "\r\n",
        "Resources:\r\n",
        "- DistilBERT paper: https://arxiv.org/abs/1910.01108\r\n",
        "- DistilBERT Tensorflow Documentation: https://huggingface.co/transformers/model_doc/distilbert.html#tfdistilbertmodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZfFboF85rIe"
      },
      "source": [
        "def build_model(base_model, trainable=False, params={}):\r\n",
        "    # TODO: build the model, with the option to freeze the parameters in distilBERT\r\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "    # Hint 1: the cls token (token for classification in bert / distilBERT)  corresponds to the first element in the sequence in DistilBERT\r\n",
        "    # Hint 2: this guide may be helpful for parameter freezing: https://keras.io/guides/transfer_learning/\r\n",
        "    # Hint 3: double check your number of parameters make sense\r\n",
        "    # Hint 4: carefully consider your final layer activation and loss function\r\n",
        "\r\n",
        "    # Refer to https://keras.io/api/layers/core_layers/input/\r\n",
        "    inputs = Input(shape = (max_seq_len,), dtype='int64', name='inputs')\r\n",
        "    masks  = Input(shape = (max_seq_len,), dtype='int64', name='masks')\r\n",
        "\r\n",
        "    base_model.trainable = trainable\r\n",
        "\r\n",
        "    dbert_output = base_model(inputs, attention_mask=masks)\r\n",
        "    dbert_last_hidden_state = dbert_output.last_hidden_state\r\n",
        "\r\n",
        "    # Any additional layers should go here\r\n",
        "    # use the 'params' as a dictionary for hyper parameter to facilitate experimentation\r\n",
        "    my_outputs = ???\r\n",
        "    probs = Dense(3, ???)(my_outputs)\r\n",
        "\r\n",
        "    model = keras.Model(inputs=[inputs, masks], outputs=probs)\r\n",
        "    model.summary()\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwmE3gvCAC8"
      },
      "source": [
        "def compile_model(model):\r\n",
        "    # TODO: compile the model, include relevant auc metrics when training\r\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "    # Hint: you may want to read up on the \"multi_label\" parameter in the keras AUC metrics\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Gc9ajwC3UO"
      },
      "source": [
        "def train_model(model, model_inputs_and_masks_train, model_inputs_and_masks_val,\r\n",
        "    y_train, y_val, batch_size, num_epochs):\r\n",
        "    # TODO: train the model\r\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\r\n",
        "\r\n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkeGty1ZGccC"
      },
      "source": [
        "def evaluate_model(model, model_inputs_and_masks_test, y_test):\n",
        "    # TODO: evaluate the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    # HINT: for pr_auc: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html \n",
        "\n",
        "    eval_dict = {\n",
        "        \"false\": {\n",
        "            \"pr_auc\": ???, \"pr_auc_random_guess\": ???, \n",
        "            \"roc_auc\": ???, \"roc_auc_random_guess\": ???, \n",
        "            \"precision\": ???, \"recall\": ???\n",
        "        }, \n",
        "        \"true\": {\n",
        "            \"pr_auc\": ???, \"pr_auc_random_guess\": ???, \n",
        "            \"roc_auc\": ???, \"roc_auc_random_guess\": ???, \n",
        "            \"precision\": ???, \"recall\": ???\n",
        "        }, \n",
        "        \"pants\": {\n",
        "            \"pr_auc\": ???, \"pr_auc_random_guess\": ???, \n",
        "            \"roc_auc\": ???, \"roc_auc_random_guess\": ???, \n",
        "            \"precision\": ???, \"recall\": ???\n",
        "        }\n",
        "    }\n",
        "    return eval_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg_oKZr5VoCU"
      },
      "source": [
        "# Execution\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xEWJaqCMTCB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "4e1f2ede-d076-4627-c6e1-ae80ba049cd4"
      },
      "source": [
        "## DO NOT Change\r\n",
        "train, val, test = load_data()\r\n",
        "train_raw_x, train_raw_y = extract_raw_text_and_y(clean_data(train))\r\n",
        "val_raw_x, val_raw_y = extract_raw_text_and_y(clean_data(val))\r\n",
        "test_raw_x, test_raw_y = extract_raw_text_and_y(clean_data(test))\r\n",
        "\r\n",
        "train_input, train_mask = encode_text(train_raw_x)\r\n",
        "train_y = prepare_target(train_raw_y)\r\n",
        "\r\n",
        "val_input, val_mask = encode_text(val_raw_x)\r\n",
        "val_y = prepare_target(val_raw_y)\r\n",
        "\r\n",
        "test_input, test_mask = encode_text(test_raw_x)\r\n",
        "test_y = prepare_target(test_raw_y)\r\n",
        "\r\n",
        "train_model_inputs_and_masks = {\r\n",
        "    'inputs' : train_input,\r\n",
        "    'masks' : train_mask\r\n",
        "}\r\n",
        "\r\n",
        "val_model_inputs_and_masks = {\r\n",
        "    'inputs' : val_input,\r\n",
        "    'masks' : val_mask\r\n",
        "}\r\n",
        "\r\n",
        "test_model_inputs_and_masks = {\r\n",
        "    'inputs' : test_input,\r\n",
        "    'masks' : test_mask\r\n",
        "}\r\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset liar (/root/.cache/huggingface/datasets/liar/default/1.0.0/1a6abd9863f27194da30fcb66988477abfa3780df3b0ad1d0032979c48ec7918)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-d7701899e5d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_raw_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_raw_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_raw_text_and_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-e5a31888549a>\u001b[0m in \u001b[0;36mencode_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbert_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#    outputs = model(**inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m             )\n\u001b[1;32m   2295\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m             \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2297\u001b[0m             \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m         )\n",
            "\u001b[0;31mAssertionError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e6WD5qyWkcm"
      },
      "source": [
        "\r\n",
        "Use the cell below to execute and experiment with your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYjCiyY-WiNY"
      },
      "source": [
        "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\r\n",
        "model, pretrained_weights = (TFDistilBertModel, 'distilbert-base-uncased')\r\n",
        "\r\n",
        "\r\n",
        "model = build_model(dbert_model, params={})\r\n",
        "#model = build_model(dbert_model, params={})\r\n",
        "\r\n",
        "model = compile_model(model)\r\n",
        "#model = compile_model(model)\r\n",
        "\r\n",
        "#model          = train_model(model, train_model_inputs_and_masks, val_model_inputs_and_masks, train_y, val_y, batch_size, num_epochs)\r\n",
        "model, history = train_model(model, train_model_inputs_and_masks, val_model_inputs_and_masks, train_y, val_y, batch_size, num_epochs)\r\n",
        "\r\n",
        "eval_dict = evaluate_model(model, test_model_inputs_and_masks, test_y)\r\n",
        "#eval_dict = evaluate_model(model, test_model_inputs_and_masks, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_KZbODkaHu_"
      },
      "source": [
        "## Conclusions (TODO)\r\n",
        "TODO: Make Your Final Conclusions About Your Model (Answer questions below, answer in this cell)\r\n",
        "- a) What is driving your model's decisions?\r\n",
        "- b) Is your model biased in some ways? If so how? \r\n",
        "- c) Does your model accomplish the objectives? If not, is your model useful and how can you justify this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xid8Xf2naNZW"
      },
      "source": [
        "# Further exploration (REMOVE ALL CODE AFTER THIS CELL BEFORE SUBMISSION)\r\n",
        "Any code after this is not evaluated, and must be removed before submission.\r\n",
        "Leaving code below will result in losing marks."
      ]
    }
  ]
}